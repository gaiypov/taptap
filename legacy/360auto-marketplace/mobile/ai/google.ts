// services/ai/google.ts
import { AI_CONFIG } from './config';

/**
 * –ê–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ–º–æ–±–∏–ª—è —Å –ø–æ–º–æ—â—å—é Google Cloud Vision API
 */
export async function analyzeWithGoogleVision(
  imageBase64: string,
  analysisType: 'full' | 'ocr' | 'object_detection' | 'text_detection'
): Promise<any> {
  try {
    console.log('ü§ñ Google Vision analysis started...', { analysisType });
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
    if (!AI_CONFIG.GOOGLE_API_KEY) {
      throw new Error('Google API key not found');
    }
    
    // –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
    const request = createGoogleVisionRequest(imageBase64, analysisType);
    
    // –í—ã–∑—ã–≤–∞–µ–º Google Vision API
    const response = await callGoogleVisionAPI(request);
    
    // –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
    const result = parseGoogleVisionResponse(response, analysisType);
    
    console.log('‚úÖ Google Vision analysis complete:', result);
    return result;
    
  } catch (error) {
    console.error('‚ùå Google Vision analysis error:', error);
    throw error;
  }
}

/**
 * –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è Google Vision API
 */
function createGoogleVisionRequest(imageBase64: string, analysisType: string): any {
  const baseRequest: {
    requests: Array<{
      image: { content: string };
      features: Array<{ type: string; maxResults?: number }>;
    }>;
  } = {
    requests: [
      {
        image: {
          content: imageBase64.replace('data:image/jpeg;base64,', ''),
        },
        features: [],
      },
    ],
  };
  
  // –î–æ–±–∞–≤–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
  switch (analysisType) {
    case 'full':
      baseRequest.requests[0].features = [
        { type: 'LABEL_DETECTION', maxResults: 20 },
        { type: 'TEXT_DETECTION', maxResults: 50 },
        { type: 'OBJECT_LOCALIZATION', maxResults: 20 },
        { type: 'WEB_DETECTION', maxResults: 10 },
      ];
      break;
      
    case 'ocr':
      baseRequest.requests[0].features = [
        { type: 'TEXT_DETECTION', maxResults: 50 },
        { type: 'DOCUMENT_TEXT_DETECTION', maxResults: 1 },
      ];
      break;
      
    case 'object_detection':
      baseRequest.requests[0].features = [
        { type: 'OBJECT_LOCALIZATION', maxResults: 20 },
        { type: 'LABEL_DETECTION', maxResults: 20 },
      ];
      break;
      
    case 'text_detection':
      baseRequest.requests[0].features = [
        { type: 'TEXT_DETECTION', maxResults: 50 },
      ];
      break;
  }
  
  return baseRequest;
}

/**
 * –í—ã–∑–æ–≤ Google Vision API
 */
async function callGoogleVisionAPI(request: any): Promise<any> {
  const response = await fetch(
    `https://vision.googleapis.com/v1/images:annotate?key=${AI_CONFIG.GOOGLE_API_KEY}`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(request),
    }
  );
  
  if (!response.ok) {
    throw new Error(`Google Vision API error: ${response.status} ${response.statusText}`);
  }
  
  const data = await response.json();
  return data;
}

/**
 * –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ Google Vision API
 */
function parseGoogleVisionResponse(response: any, analysisType: string): any {
  try {
    const annotations = response.responses[0];
    
    if (analysisType === 'ocr') {
      return parseOCRResponse(annotations);
    }
    
    if (analysisType === 'object_detection') {
      return parseObjectDetectionResponse(annotations);
    }
    
    if (analysisType === 'text_detection') {
      return parseTextDetectionResponse(annotations);
    }
    
    // –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    return parseFullAnalysisResponse(annotations);
    
  } catch (error) {
    console.error('Error parsing Google Vision response:', error);
    
    // Fallback –¥–∞–Ω–Ω—ã–µ
    return {
      brand: 'Unknown',
      model: 'Unknown',
      year: 2020,
      color: 'Unknown',
      mileage: 0,
      location: '–ë–∏—à–∫–µ–∫',
      videoUrl: 'mock://video',
      thumbnailUrl: 'https://picsum.photos/800/600',
      aiAnalysis: {
        condition: 'good',
        conditionScore: 80,
        damages: [],
        estimatedPrice: { min: 2000000, max: 2500000 },
        features: [],
      },
    };
  }
}

/**
 * –ü–∞—Ä—Å–∏–Ω–≥ OCR –æ—Ç–≤–µ—Ç–∞
 */
function parseOCRResponse(annotations: any): any {
  const textAnnotations = annotations.textAnnotations || [];
  const fullText = textAnnotations[0]?.description || '';
  
  // –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–±–µ–≥–µ
  const mileageMatch = fullText.match(/(\d{1,6})\s*(–∫–º|km|—Ç—ã—Å|—Ç—ã—Å—è—á)/i);
  const mileage = mileageMatch ? parseInt(mileageMatch[1]) * 1000 : 0;
  
  // –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥
  const yearMatch = fullText.match(/(19|20)\d{2}/);
  const year = yearMatch ? parseInt(yearMatch[0]) : 2020;
  
  return {
    mileage,
    year,
    fullText,
    extractedText: textAnnotations.slice(1).map((text: any) => text.description),
  };
}

/**
 * –ü–∞—Ä—Å–∏–Ω–≥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
 */
function parseObjectDetectionResponse(annotations: any): any {
  const localizedObjects = annotations.localizedObjectAnnotations || [];
  const labels = annotations.labelAnnotations || [];
  
  // –ò—â–µ–º –∞–≤—Ç–æ–º–æ–±–∏–ª—å
  const carLabels = labels.filter((label: any) => 
    label.description.toLowerCase().includes('car') ||
    label.description.toLowerCase().includes('vehicle') ||
    label.description.toLowerCase().includes('automobile')
  );
  
  // –ò—â–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è
  const damageLabels = labels.filter((label: any) => 
    label.description.toLowerCase().includes('scratch') ||
    label.description.toLowerCase().includes('dent') ||
    label.description.toLowerCase().includes('damage') ||
    label.description.toLowerCase().includes('rust')
  );
  
  return {
    carDetected: carLabels.length > 0,
    carConfidence: carLabels[0]?.score || 0,
    damages: damageLabels.map((label: any) => ({
      type: label.description.toLowerCase(),
      confidence: label.score,
      location: 'unknown',
    })),
    objects: localizedObjects,
  };
}

/**
 * –ü–∞—Ä—Å–∏–Ω–≥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
 */
function parseTextDetectionResponse(annotations: any): any {
  const textAnnotations = annotations.textAnnotations || [];
  
  return {
    texts: textAnnotations.map((text: any) => ({
      text: text.description,
      confidence: text.score,
      boundingBox: text.boundingPoly,
    })),
  };
}

/**
 * –ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
 */
function parseFullAnalysisResponse(annotations: any): any {
  const labels = annotations.labelAnnotations || [];
  const textAnnotations = annotations.textAnnotations || [];
  const webEntities = annotations.webDetection?.webEntities || [];
  
  // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞—Ä–∫—É –∏ –º–æ–¥–µ–ª—å –ø–æ –ª–µ–π–±–ª–∞–º
  const carBrands = ['Toyota', 'BMW', 'Mercedes', 'Audi', 'Lexus', 'Honda', 'Ford', 'Chevrolet'];
  const detectedBrand = labels.find((label: any) => 
    carBrands.some(brand => label.description.toLowerCase().includes(brand.toLowerCase()))
  );
  
  // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç
  const colorLabels = labels.filter((label: any) => 
    ['white', 'black', 'red', 'blue', 'green', 'yellow', 'silver', 'gray'].includes(label.description.toLowerCase())
  );
  
  // –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ–±–µ–≥ –∏–∑ —Ç–µ–∫—Å—Ç–∞
  const fullText = textAnnotations[0]?.description || '';
  const mileageMatch = fullText.match(/(\d{1,6})\s*(–∫–º|km|—Ç—ã—Å|—Ç—ã—Å—è—á)/i);
  const mileage = mileageMatch ? parseInt(mileageMatch[1]) * 1000 : 0;
  
  // –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥
  const yearMatch = fullText.match(/(19|20)\d{2}/);
  const year = yearMatch ? parseInt(yearMatch[0]) : 2020;
  
  return {
    brand: detectedBrand?.description || 'Unknown',
    model: 'Unknown', // Google Vision –Ω–µ –º–æ–∂–µ—Ç —Ç–æ—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å
    year,
    color: colorLabels[0]?.description || 'Unknown',
    mileage,
    location: '–ë–∏—à–∫–µ–∫',
    videoUrl: 'mock://video',
    thumbnailUrl: 'https://picsum.photos/800/600',
    aiAnalysis: {
      condition: 'good',
      conditionScore: 80,
      damages: [],
      estimatedPrice: { min: 2000000, max: 2500000 },
      features: labels.slice(0, 5).map((label: any) => label.description),
    },
  };
}

/**
 * –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–æ–±–µ–≥–∞ —Å –ø–æ–º–æ—â—å—é OCR
 */
export async function extractMileageWithGoogle(imageBase64: string): Promise<{
  mileage: number;
  confidence: number;
  extractedText: string;
}> {
  try {
    const result = await analyzeWithGoogleVision(imageBase64, 'ocr');
    
    return {
      mileage: result.mileage || 0,
      confidence: 0.8,
      extractedText: result.fullText || '',
    };
    
  } catch (error) {
    console.error('Google mileage extraction error:', error);
    
    return {
      mileage: 0,
      confidence: 0,
      extractedText: '',
    };
  }
}

/**
 * –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π —Å Google Vision
 */
export async function detectDamagesWithGoogle(imageBase64: string): Promise<{
  damages: any[];
  overallCondition: string;
  conditionScore: number;
}> {
  try {
    const result = await analyzeWithGoogleVision(imageBase64, 'object_detection');
    
    return {
      damages: result.damages || [],
      overallCondition: 'good',
      conditionScore: 80,
    };
    
  } catch (error) {
    console.error('Google damage detection error:', error);
    
    return {
      damages: [],
      overallCondition: 'good',
      conditionScore: 80,
    };
  }
}
